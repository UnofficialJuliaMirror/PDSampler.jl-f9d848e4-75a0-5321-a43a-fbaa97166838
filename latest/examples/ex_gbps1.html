<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Global BPS (Truncated Gaussian) · PDMP.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Ubuntu+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/highlightjs/default.css" rel="stylesheet" type="text/css"/><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>PDMP.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" action="../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../index.html">Introduction</a></li><li><span class="toctext">Examples</span><ul><li class="current"><a class="toctext" href="ex_gbps1.html">Global BPS (Truncated Gaussian)</a><ul class="internal"></ul></li><li><a class="toctext" href="ex_lbps1.html">Local BPS (Chain of Gaussians)</a></li></ul></li><li><span class="toctext">Technical Documentation</span><ul><li><a class="toctext" href="../techdoc/types.html">Types</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Examples</li><li><a href="ex_gbps1.html">Global BPS (Truncated Gaussian)</a></li></ul><a class="edit-page" href="https://github.com/alan-turing-institute/PDMP.jl/tree/8c530df432066eb8b745e285b23aeb80e1294e26/docs/src/examples/ex_gbps1.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/></header><p>(<em>the code for this example can be found <a href="https://github.com/alan-turing-institute/PDMP.jl/blob/master/test/ex_gbps1.jl">here</a></em>)</p><h1><a class="nav-anchor" id="Global-BPS-(Truncated-Gaussian)-1" href="#Global-BPS-(Truncated-Gaussian)-1">Global BPS (Truncated Gaussian)</a></h1><p>In this example we <strong>XXXXXXX</strong></p><p>Start by loading the library:</p><pre><code class="language-julia">using PDMP</code></pre><p>you will then need to define two elements:</p><ol><li><p>a geometry (boundaries)</p></li><li><p>an energy (gradient of the log-likelihood of the target)</p></li></ol><p>At the moment, the package can handle unconstrained geometries and polygonal domains (<strong>see XXXXX</strong>). Let&#39;s say we want to be constrained to the positive orthan in 2D:</p><pre><code class="language-julia">p = 2
# normal to faces and intercepts
ns, a = eye(p), zeros(p)
geom  = Polygonal(ns, a)
# for a given ray, which boundary does it hit?
nextbd(x, v) = nextboundary(geom, x, v)</code></pre><p>Here <code>ns</code> and <code>a</code> are the normals and the intercepts of the faces. The type <code>Polygonal</code> encapsulates the geometry. The function <code>nextboundary</code> returns the next boundary on the current ray <code>[x,x+tv]</code> with <code>t&gt;0</code> as well as the time of the hit.</p><p>We then need to specify a model: we need to define a function of the form <code>gradll(x)</code> which can return the gradient of the log-likelihood at some point <code>x</code>. Here, let us consider a 2D gaussian.</p><pre><code class="language-julia"># build a valid precision matrix, the cholesky decomposition of
# the covariance matrix will be useful later to build a sensible
# starting point.
srand(12)
P1  = randn(p,p)
P1 *= P1&#39;
P1 += norm(P1)/100*eye(p)
C1  = inv(P1); C1 += C1&#39;; C1/=2;
L1  = cholfact(C1)
mu  = zeros(p)+1.
mvg = MvGaussianCanon(mu, P1)</code></pre><p>Here, we have defined the gaussian through the &quot;Canonical&quot; representation (<strong>see XXXXX</strong>) i.e.: by specifying a mean and a precision matrix.</p><p>The gradient of the log-likelihood is then given by</p><pre><code class="language-julia">gradll(x) = gradloglik(mvg, x)</code></pre><p><strong>Remark</strong>: if you want to implement your own model, you should define your model in (<strong>XXXXXX</strong>) and make sure it implements a <code>gradloglik</code> function.</p><p>Next, we need to define the function which can return the first arrival time of the Inhomogenous Poisson Process (<strong>cf. algorithm</strong>). Note that you could be using <code>nextevent_zz</code> here as well if you wanted to use the Zig-Zag sampler (and you could implement other kernels as well, see <strong>HERE XXXXX</strong>).</p><pre><code class="language-julia">nextev(x, v) = nextevent_bps(mvg, x, v)</code></pre><p>For a Gaussian (and some other simple distributions), this is analytical through an inversion-like method (<strong>cf. algorithm</strong>). Another approach is the thinning approach using a bounding intensity. At the moment thinning with a linear bound is implemented (<strong>cf XXXXX</strong>).</p><p>Finally, you need to specify the parameters of the simulation such as the starting point and velocity, the length of the path generated, the rate of refreshment and the maximum number of gradient evaluations. (<strong>see discussion</strong>)</p><pre><code class="language-julia">T    = 1000.0   # length of path generated
lref = 2.0      # rate of refreshment
x0   = mu+L1[:L]*randn(p) # sensible starting point
v0   = randn(p) # starting velocity
v0  /= norm(v0) # put it on the sphere (not necessary)
# Define a simulation
sim = Simulation( x0, v0, T, nextev, gradll,
            nextbd, lref ; maxgradeval = 10000)</code></pre><p>And finally, generate the path and recover some details about the simulation.</p><pre><code class="language-julia">(path, details) = simulate(sim)</code></pre><p>The <code>path</code> object belongs to the type <code>Path</code> and can be sampled using <code>samplepath</code>.</p><p>A crude test is to check that the estimated mean obtained through quadrature along the path yields a similar result as a basic Monte Carlo estimator.</p><pre><code class="language-julia"># Building a basic MC estimator
sN = 1000
s  = repmat(mu,1,sN)+L1[:L]*randn(p,sN)
mt = zeros(2)
np = 0
# Sum for all samples in the positive orthan
ss = [s; ones(sN)&#39;]
mt = sum(ss[:,i] for i in 1:sN if !any(e-&gt;e&lt;0, ss[1:p,i]))
mt = mt[1:p]/mt[end]</code></pre><p>You can now compare the norm of <code>mt</code> to <code>pathmean(path)</code> and you will see that the relative error is below 5%.</p><footer><hr/><a class="previous" href="../index.html"><span class="direction">Previous</span><span class="title">Introduction</span></a><a class="next" href="ex_lbps1.html"><span class="direction">Next</span><span class="title">Local BPS (Chain of Gaussians)</span></a></footer></article></body></html>
